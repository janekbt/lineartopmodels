---
title: "Linear top models"
subtitle: "A predictive model of house prices in King County, USA"
author: "Nicolas Carmona, Niklas Tillenburg, Janek Teders"
date: "December 16, 2018"
output: 
  ioslides_presentation:
    widescreen: true
---

```{r setup, include=FALSE}
set.seed(1234)
#install.packages("kableExtra")
#install.packages("jpeg")
#install.packages("png")
#install.packages("kable")
#install.packages("gridExtra")
library(lubridate)
library(gridExtra)
library(MASS)
library(png)
library(jpeg)
library(tidyverse)
library(knitr)
library(car)
library(faraway)
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, warning=FALSE)
library(kableExtra)
options("kableExtra.html.bsTable" = T)

raw_data <- readRDS("raw_data.rds")
full_data <- readRDS("full_data.rds")
full_data_woo <- readRDS("full_data_woo.rds")
```

## The dataset

- Houses sold between May 2014 and May 2015
- Observations: **`r nrow(raw_data)`**
- Variables: **`r ncol(raw_data)`**


## Variables

```{r echo=FALSE}
matrix(colnames(raw_data), ncol = 3) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Response variable inspection

```{r echo=FALSE, fig.align = "center", fig.width=8, fig.height=6}
par(mfrow = c(1,2))
truehist(raw_data$price,
         xlab = "price")
a <- qqPlot(raw_data$price,
            xlab = "quantiles",
            ylab = "")
```

## Response variable transformation

```{r echo=FALSE, fig.align = "center"}
par(mfrow = c(1,2))
truehist(log10(raw_data$price),
         xlab = "price")
a <- qqPlot(log10(raw_data$price),
            xlab = "quantiles",
            ylab = "")
```

## How are we going to select the models?

* Problem: p-value and multiple testing
* Alternative criteria:
    + $AIC$
    + $BIC$
    + $R^2_{adj.}$
    + $RMSE$

## Preliminary data formating

**Changes**:

  - **square feet** into **square meters**
  - waterfront and renovated into a **factor** variable
  - log10 of price (response variable)
  - split date into week and month of the year


```{r}
data_wo_new_vars <- full_data %>%
  select(-wasViewed, -renovated, -mean_price_zip)

model_1 <- lm(price ~ ., data = data_wo_new_vars)
```

## First model {.flexbox .vcenter}

<div class="columns-2">

```{r}
knitr::include_graphics("screenshots/summary_2.png")
```

```{r include=FALSE}
a <- round(summary(model_1)$adj.r.squared, 4)
b <- round(AIC(model_1), 4)
c <- round(BIC(model_1), 4)
```


**Criteria:**

  - $R^2_{adj}$: `r a`
  - $AIC$: `r b`
  - $BIC$: `r c`
</div>

## Outliers

```{r echo=FALSE, fig.align = "center"}
par(mfrow = c(1,2))
plot(model_1, which=5)
plot(model_1, which=4)

#head(sort(cooks.distance(model_1), decreasing = T), 4)
```

## Post outlier removal comparison

```{r warning=FALSE}
intermediate_1 <- full_data_woo %>%
  select(-wasViewed, -renovated, -mean_price_zip)

model_2 <- intermediate_1 %>%
  lm(data = . , price ~ .)

B <- 10
k <- 10
n <- nrow(intermediate_1)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_1)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_1[folds != i,]
    test <- intermediate_1[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_2_mrmse <- mean(sqrt(results))
model_2_sdrmse <- sd(sqrt(results))

intermediate_2 <- data_wo_new_vars

B <- 10
k <- 10
n <- nrow(intermediate_2)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_2)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_2[folds != i,]
    test <- intermediate_2[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_1_mrmse <- mean(sqrt(results))
model_1_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_1_mrmse, model_2_mrmse)
SD_RMSE <- rbind(model_1_sdrmse, model_2_sdrmse)

cbind(AIC(model_1, model_2), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```

* Observations:
    + Dropping extreme outlier improves the model

## Creating new variables

* Average price by zipcode
    + sampling 20% of the data
    + computing average price by zipcode
    + adding computed averages to remaining 80%

* Factorize:
    + view variable into viewed or not viewed
    + year_renovated into was renovated at all or not

* Still keeping the untransformed data

```{r warning=FALSE}
intermediate_3 <- full_data_woo
model_3 <- lm(price ~ ., data = intermediate_3)


B <- 10
k <- 10
n <- nrow(intermediate_3)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_3)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_3[folds != i,]
    test <- intermediate_3[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_3_mrmse <- mean(sqrt(results))
model_3_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_2_mrmse, model_3_mrmse)
SD_RMSE <- rbind(model_2_sdrmse, model_3_sdrmse)

cbind(AIC(model_2, model_3), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```

## Variable preselection (Part I)

### Correlation analysis 

```{r echo=FALSE, warning=FALSE}
corrs <- full_data %>%
  dplyr::select(-waterfront, -renovated, - wasViewed) %>%
  cor(.) %>%
  .[,1] %>%
  abs(.) %>%
  sort(.) %>%
  as.matrix(., nrow(length(.)))


good_corr <- corrs %>%
  rownames(.) %>%
  .[10:length(.)]

corrs_names = rownames(corrs)
corrs = cbind(corrs_names, round(corrs, 4))
rownames(corrs) = NULL
colnames(corrs) = NULL

cbind(corrs[1:7,], corrs[8:14,], corrs[15:21,]) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
## Variable preselection 

* Hypothesis:
    + We observe a big jump in correlation from 0.107 to 0.314
    + Dropping all variables below 0.314 might decrease prediction error





## Fourth model

```{r warning=FALSE}

intermediate_4 <- full_data_woo %>%
  dplyr::select(one_of(good_corr), renovated, waterfront, wasViewed)

model_4 <- lm(price ~ ., data = intermediate_4)

s_lmo_2 <- summary(model_4)

#drop1(model_3)

B <- 10
k <- 10
n <- nrow(intermediate_4)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_4)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_4[folds != i,]
    test <- intermediate_4[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_4_mrmse <- mean(sqrt(results))
model_4_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_3_mrmse, model_4_mrmse)
SD_RMSE <- rbind(model_3_sdrmse, model_4_sdrmse)

cbind(AIC(model_3, model_4), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```

## Variable preselection (Part II)

* **sqm_living** is a linear combination of **sqm_basement** and **sqm_above**.
* Deleting variables because of redundancy
    + choosing the best transformations first
    + then drop the variable of the worse perfoming model

```{r}
set.seed(1234)
intermediate_5 <- full_data_woo %>%
  mutate(
    sqm_above = sqrt(sqm_above),
    sqm_basement = sqrt(sqm_basement)
  ) %>%
  dplyr::select(-sqm_living) 

model_5 <- lm(data = intermediate_5, price ~ .)

intermediate_6 <- full_data_woo %>%
  mutate(
    sqm_living = sqrt(sqm_living)
  ) %>%
  dplyr::select(-sqm_above, -sqm_basement) 

model_6 <- lm(data = intermediate_6, price ~ .)

s_model_5 <- summary(model_5)
s_model_6 <- summary(model_6)

B <- 10
k <- 10
n <- nrow(intermediate_5)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_5)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_5[folds != i,]
    test <- intermediate_5[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_5_mrmse <- mean(sqrt(results))
model_5_sdrmse <- sd(sqrt(results))

B <- 10
k <- 10
n <- nrow(intermediate_6)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_6)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_6[folds != i,]
    test <- intermediate_6[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_6_mrmse <- mean(sqrt(results))
model_6_sdrmse <- sd(sqrt(results))

row_names <- c("Model with sqm_above & sqm_basement", "Model with sqm_living")
col_names <- c("R^2 adjust.", "AIC", "BIC", "Mean_RMSE", "SD_RMSE")
a <- matrix(c(round(s_model_5$adj.r.squared, 4),
              round(AIC(model_5), 4),
              round(BIC(model_5), 4),
              round(model_5_mrmse, 4),
              round(model_5_sdrmse, 4),
              round(s_model_6$adj.r.squared, 4),
              round(AIC(model_6), 4),
              round(BIC(model_6), 4),
              round(model_6_mrmse, 4),
              round(model_6_sdrmse, 4)),
            ncol = 5,
            byrow = T,
            dimnames = list(row_names, col_names))
a %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```


## Variable Transformation

```{r include=FALSE}
transformed_data <- full_data_woo %>%
  select(-sqm_living) %>%
  mutate(
    sqm_above = sqrt(sqm_above),
    sqm_basement = sqrt(sqm_basement),
    floors = log10(floors),
    bathrooms = bathrooms^(1/5),
    sqm_living15 = log(sqm_living15),
    mean_price_zip = mean_price_zip,
    grade = log10(grade),
    condition = log10(condition),
    yr_built = log10(yr_built),
    lat = log10(lat),
    week_of_year = log10(week_of_year),
    month_of_year = log10(month_of_year),
    sqm_lot15 = log10(sqm_lot15)
  )

ncol(transformed_data)
```

## Final model

```{r}
set.seed(1234)
model_7 <- transformed_data %>%
  lm(data = ., price ~ .)

B <- 10
k <- 10
n <- nrow(transformed_data)
folds <- sample(rep(c(1:k), length.out = nrow(transformed_data)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- transformed_data[folds != i,]
    test <- transformed_data[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_7_mrmse <- mean(sqrt(results))
model_7_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_1_mrmse, model_5_mrmse, model_7_mrmse)
SD_RMSE <- rbind(model_1_sdrmse, model_5_sdrmse, model_7_sdrmse)

cbind(AIC(model_1, model_5, model_7), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```



