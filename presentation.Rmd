---
title: "Linear top models"
subtitle: "A predictive model of house prices in King County, USA"
author: "Nicolas Carmona, Niklas Tillenburg, Janek Teders"
date: "December 16, 2018"
output: 
  ioslides_presentation:
    widescreen: true
---

```{r setup, include=FALSE}
#install.packages("kableExtra")
#install.packages("jpeg")
#install.packages("png")
#install.packages("kable")
#install.packages("gridExtra")
library(lubridate)
library(gridExtra)
library(MASS)
library(png)
library(jpeg)
library(tidyverse)
library(knitr)
library(car)
library(faraway)
knitr::opts_chunk$set(echo = FALSE)
library(kableExtra)
options("kableExtra.html.bsTable" = T)

raw_data <- readRDS("raw_data.rds")
full_data <- readRDS("full_data.rds")
full_data_woo <- readRDS("full_data_woo.rds")
```

## The dataset

- Houses sold between May 2014 and May 2015
- Observations: **`r nrow(raw_data)`**
- Variables: **`r ncol(raw_data)`**


## Variables

```{r echo=FALSE}
matrix(colnames(raw_data), ncol = 3) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Response variable inspection

```{r echo=FALSE}
par(mfrow = c(1,2))
truehist(raw_data$price,
         xlab = "price")
a <- qqPlot(raw_data$price,
            xlab = "quantiles",
            ylab = "")
```

## Response variable transformation

```{r echo=FALSE}
par(mfrow = c(1,2))
truehist(log10(raw_data$price),
         xlab = "price")
a <- qqPlot(log10(raw_data$price),
            xlab = "quantiles",
            ylab = "")
```

## How are we going to select the models?

* Problem: p-value and multiple testing
* Alternative criteria:
    + $AIC$
    + $BIC$
    + $R^2_{adj.}$
    + $RMSE$

## Preliminary data formating

**Changes**:

  - **square feet** into **square meters**
  - waterfront and renovated into a **factor** variable
  - log10 of price (response variable)
  - split date into week and month of the year


```{r}
data_wo_new_vars <- full_data %>%
  select(-wasViewed, -renovated, -mean_price_zip)

model_1 <- lm(price ~ ., data = data_wo_new_vars)
```

## First model {.flexbox .vcenter}

<div class="columns-2">

```{r}
knitr::include_graphics("screenshots/summary_2.png")
```

```{r include=FALSE}
a <- round(summary(model_1)$adj.r.squared, 4)
b <- round(AIC(model_1), 4)
c <- round(BIC(model_1), 4)
```


**Criteria:**

  - $R^2_{adj}$: `r a`
  - $AIC$: `r b`
  - $BIC$: `r c`
</div>

## Outliers

```{r echo=FALSE, fig.align = "center"}
par(mfrow = c(1,2))
plot(model_1, which=5)
plot(model_1, which=4)
```

## Post outlier removal comparison

```{r warning=FALSE}
intermediate_1 <- full_data_woo %>%
  select(-wasViewed, -renovated, -mean_price_zip)

model_2 <- intermediate_1 %>%
  lm(data = . , price ~ .)

B <- 10
k <- 10
n <- nrow(intermediate_1)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_1)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_1[folds != i,]
    test <- intermediate_1[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_2_mrmse <- mean(sqrt(results))
model_2_sdrmse <- sd(sqrt(results))

intermediate_2 <- data_wo_new_vars

B <- 10
k <- 10
n <- nrow(intermediate_2)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_2)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_2[folds != i,]
    test <- intermediate_2[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_1_mrmse <- mean(sqrt(results))
model_1_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_1_mrmse, model_2_mrmse)
SD_RMSE <- rbind(model_1_sdrmse, model_2_sdrmse)

cbind(AIC(model_1, model_2), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```

* Observations:
    + Dropping extreme outlier improves the model

## Creating new variables

* Average price by zipcode
    + sampling 20% of the data
    + computing average price by zipcode
    + adding computed averages to remaining 80%

* Factorize:
    + view variable into viewed or not viewed
    + year_renovated into was renovated at all or not

* Still keeping the untransformed data

```{r}
intermediate_3 <- full_data_woo
model_3 <- lm(price ~ ., data = intermediate_3)


B <- 10
k <- 10
n <- nrow(intermediate_3)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_3)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_3[folds != i,]
    test <- intermediate_3[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_3_mrmse <- mean(sqrt(results))
model_3_sdrmse <- sd(sqrt(results))

Mean_RMSE <- rbind(model_2_mrmse, model_3_mrmse)
SD_RMSE <- rbind(model_2_sdrmse, model_3_sdrmse)

cbind(AIC(model_2, model_3), Mean_RMSE, SD_RMSE) %>%
  kable() %>%
  kable_styling()
```

## Variable preselection (Part I)

### Correlation analysis 

```{r echo=FALSE, warning=FALSE}
corrs <- full_data %>%
  dplyr::select(-waterfront, -renovated, - wasViewed) %>%
  cor(.) %>%
  .[,1] %>%
  abs(.) %>%
  sort(.) %>%
  as.matrix(., nrow(length(.)))


good_corr <- corrs %>%
  rownames(.) %>%
  .[10:length(.)]

corrs_names = rownames(corrs)
corrs = cbind(corrs_names, round(corrs, 4))
rownames(corrs) = NULL
colnames(corrs) = NULL

cbind(corrs[1:7,], corrs[8:14,], corrs[15:21,]) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
## Variable preselection 

* Cutoff:
    + We observe a big jump from 0.107 to 0.314
    + Dropping all variables below 0.314
    + We are now left with 11 variables (plus the 2 factors)




## Fourth model

```{r warning=FALSE}

intermediate_4 <- full_data_woo %>%
  dplyr::select(one_of(good_corr), renovated, waterfront, wasViewed)

model_4 <- lm(price ~ ., data = intermediate_4)

s_lmo_2 <- summary(model_4)

#drop1(model_3)

B <- 10
k <- 10
n <- nrow(intermediate_4)
folds <- sample(rep(c(1:k), length.out = nrow(intermediate_4)))
results <- matrix(0, nrow = k, ncol = B)
for (b in 1:B){
  for (i in 1:k) {
    training <- intermediate_4[folds != i,]
    test <- intermediate_4[folds == i,]

    lmo <- lm(data = training, price ~ .)
    predict <- predict(lmo, test)
    
    results[i,b] <- sum((10^test$price - 10^predict)^2)/length(test$price)
  }
}
model_4_mrmse <- mean(sqrt(results))
model_4_sdrmse <- sd(sqrt(results))
```


<div class="columns-2">

**Old model:**

  - $R^2_{adj}$: `r round(result_1$adj.r.squared, 4)`
  - $AIC$: `r round(AIC(lmo_1), 4)`
  - $BIC$: `r round(BIC(lmo_1), 4)`

\newline
\newline
\newline
\newline
\newline

**Second model:**

  - $R^2_{adj}$: `r round(s_lmo_2$adj.r.squared, 4)`
  - $AIC$: `r round(AIC(lmo_2), 4)`
  - $BIC$: `r round(BIC(lmo_2), 4)`
  
</div>

## Variable preselection (Part II)

- **sqm_living** is a linear combination of **sqm_basement** and **sqm_above**.

```{r}
lmo_AB <- dat_new_1 %>%
  dplyr::select(-sqm_living) %>%
  lm(data = ., price ~ .)

lmo_L <- dat_new_1 %>%
  dplyr::select(-sqm_above, -sqm_basement) %>%
  lm(data = ., price ~ .)

s_lmo_AB <- summary(lmo_AB)
s_lmo_L <- summary(lmo_L)

row_names <- c("Model with sqm_above & sqm_basement", "Model with sqm_living")
col_names <- c("R^2 adjust.", "AIC", "BIC")
a <- matrix(c(round(s_lmo_AB$adj.r.squared, 4),
              round(AIC(lmo_AB), 4),
              round(BIC(lmo_AB), 4),
              round(s_lmo_L$adj.r.squared, 4),
              round(AIC(lmo_L), 4),
              round(BIC(lmo_L), 4)),
            ncol = 3,
            byrow = T,
            dimnames = list(row_names, col_names))
a %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))


```

## Variable Transformation


```{r echo=FALSE}
dat_new_2 <- dat_new_1 %>%
  dplyr::select(-sqm_basement, -sqm_above)

lmo_sqrt_sqm_living <- dat_new_2 %>%
  lm(data = ., price ~ . - sqm_living + sqrt(sqm_living))

BIC(lmo_L,lmo_sqrt_sqm_living)


lmo_sqrt_lat <- dat_new_2 %>%
  lm(data = ., price ~ . - lat + log10(lat))

BIC(lmo_L,lmo_sqrt_lat)
```



```{r include=FALSE}
dat_new_3 <- dat_new_2 %>%
  mutate(
    floors = log10(floors),
    bedrooms = sqrt(bedrooms),
    wasViewed = factor(ifelse(view > 0, 1, 0)),
    bathrooms = bathrooms^(1/5),
    sqm_living15 = log(sqm_living15),
    mean_price_zip = log10(mean_price_zip),
    grade = log10(grade),
    sqm_living = sqrt(sqm_living)
  )

ncol(dat_new_3)
```

## Final model

```{r}
test <- result %>%
  lm(data = ., price ~ .)

test_new <- dat_new_3 %>%
  lm(data = ., price ~ .)

summary(test)$adj.r.squared
summary(test_new)$adj.r.squared
BIC(test, test_new)
ncol(result)
```

```{r}
k <- 5
n <- nrow(result)
folds <- sample(rep(c(1:k), length.out = nrow(result)))
results <- numeric(k)
for (i in 1:k) {
  training <- result[folds != i,]
  test <- result[folds == i,]

  lmo <- result %>%
  dplyr::select(-waterfront, -renovated) %>%
  lm(data = ., price ~ .)
  predict <- predict(lmo, test)

  results[i] <- sum((10^test$price - 10^predict)^2)/length(test$price)
}
mean(sqrt(results))
sd(sqrt(results))
```

```{r}
k <- 10
n <- nrow(dat_new_3)
folds <- sample(rep(c(1:k), length.out = nrow(dat_new_3)))
results <- numeric(k)
for (i in 1:k) {
  training <- dat_new_3[folds != i,]
  test <- dat_new_3[folds == i,]

  lmo <- lm(data = training, price ~ .)
  predict <- predict(lmo, test)


  #break
  results[i] <- sum((10^test$price - 10^predict)^2)/length(test$price)
}
mean(sqrt(results))
sd(sqrt(results))
```

